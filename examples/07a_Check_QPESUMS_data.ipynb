{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quality Check on QPESUMS Data\n",
    "\n",
    "During the *autoencoder* process, we confirmed a data problem: the QPESUMS on 20140614 is up-side-down while records of other time are not. This prompt us to do a more detailed check on the QPESUMS dataset, since we are not sure how may other records are corrupted, nor any systematic error pattern is found so far.\n",
    "\n",
    "We want to perform a sampling and checking process on this totally **34,369** records. Since we concern more about the heavy rainfall cases, hence we want to include as many these cases as possible.\n",
    "\n",
    "The size of the dataset and its subsets are summarized in the following table:\n",
    "\n",
    "|dataset|number of records|\n",
    "|-------|-----------------|\n",
    "|Full|34369|\n",
    "|1mm/hr|11260|\n",
    "|5mm/hr|4456|\n",
    "|10mm/hr|2150|\n",
    "|20mm/hr|858|\n",
    "|40mm/hr|236|\n",
    "|Typhoon warning|1517|\n",
    "\n",
    "\n",
    "Hence, our sampling scheme is:\n",
    "\n",
    "- Sample 500 files and check with the stored Radar data\n",
    "  - all cases with (prec >= 40mm/hr): 236\n",
    "  - 200 with typhoon warning\n",
    "  - 64 from others\n",
    "    \n",
    "\n",
    "## Read Timestamps\n",
    "\n",
    "First let's read in the timestamps and filter out duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11481, 1)\n",
      "(239, 1)\n",
      "(1584, 2)\n",
      "    timestamp typhoon\n",
      "0  2013071101  SOULIK\n",
      "1  2013071102  SOULIK\n",
      "2  2013071103  SOULIK\n",
      "3  2013071104  SOULIK\n",
      "4  2013071105  SOULIK\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Read date list\n",
    "tsp01 = pd.read_csv('data/dates_p01.csv')\n",
    "tsp40 = pd.read_csv('data/dates_p40.csv')\n",
    "tstyw = pd.read_csv('data/dates_typhoon.csv')\n",
    "\n",
    "# Check dimension\n",
    "print(tsp01.shape)\n",
    "print(tsp40.shape)\n",
    "print(tstyw.shape)\n",
    "\n",
    "print(tstyw.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11242, 1)\n",
      "(10340, 1)\n",
      "(1543, 2)\n"
     ]
    }
   ],
   "source": [
    "# Filter out overlapped time-stamps\n",
    "tsp01 = tsp01.loc[~tsp01.date.isin(tsp40.date),:]\n",
    "print(tsp01.shape)\n",
    "tsp01 = tsp01.loc[~tsp01.date.isin(tstyw.timestamp),:]\n",
    "print(tsp01.shape)\n",
    "\n",
    "tstyw = tstyw.loc[~tstyw.timestamp.isin(tsp40.date),:]\n",
    "print(tstyw.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling\n",
    "\n",
    "The most common tool for random sampling is [`numpy.random.choice`](https://docs.scipy.org/doc/numpy-1.16.0/reference/generated/numpy.random.choice.html). We need to specify `replace=False` to avoid picking the same timestamp twice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239\n",
      "439\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "# All HR cases\n",
    "ts_selected = list(tsp40.date)\n",
    "print(len(ts_selected))\n",
    "# Add 200 samples from Typhoon cases\n",
    "tmp = np.random.choice(tstyw.timestamp, 200, replace=False)\n",
    "ts_selected += list(tmp)\n",
    "print(len(ts_selected))\n",
    "# Add 61 samples from prec>=1mm/hr\n",
    "ts_selected += list(np.random.choice(tsp01.date, 61, replace=False))\n",
    "print(len(ts_selected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499\n"
     ]
    }
   ],
   "source": [
    "# Check duplicates\n",
    "print(len(set(ts_selected)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    timestamp\n",
      "0  2013010818\n",
      "1  2013011009\n",
      "2  2013011017\n",
      "3  2013011108\n",
      "4  2013021606\n"
     ]
    }
   ],
   "source": [
    "ts_selected.sort()\n",
    "output = pd.DataFrame({'timestamp':ts_selected})\n",
    "print(output.head())\n",
    "output.to_csv('data/sampled_timestamp.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
