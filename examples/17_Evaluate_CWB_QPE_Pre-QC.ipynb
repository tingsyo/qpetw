{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate CWB QPE Pre-QC\n",
    "\n",
    "In the previous example we have developed tools for deriving time-by-station QPE from CWB pre-QC data. Now we are going to evalute the results against station records.\n",
    "\n",
    "## Read QPE data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>466880</th>\n",
       "      <th>466910</th>\n",
       "      <th>466920</th>\n",
       "      <th>466930</th>\n",
       "      <th>466940</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201401010800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014010108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201401010900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014010109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201401011000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014010110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201401011100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014010111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201401011200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014010112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      timestamp  466880  466910  466920  466930  466940        date\n",
       "0  201401010800     0.0     0.0     0.0     0.0     0.0  2014010108\n",
       "1  201401010900     0.0     0.0     0.0     0.0     0.0  2014010109\n",
       "2  201401011000     0.0     0.0     0.0     0.0     0.0  2014010110\n",
       "3  201401011100     0.0     0.0     0.0     0.0     0.0  2014010111\n",
       "4  201401011200     0.0     0.0     0.0     0.0     0.0  2014010112"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stid = ['466880','466910','466920','466930','466940']\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "qpe = pd.read_csv('../ws.cwb/cwbqpe_eval.csv')\n",
    "qpe = qpe.loc[:,['timestamp']+stid]\n",
    "\n",
    "qpe['date'] = qpe['timestamp'].apply(lambda x: int(x/100))\n",
    "qpe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Station Data and Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Station Precipitation:\n",
      "         date  C0A580  C0A970  466940  C0A540  C0A550  C0A9A0  C0AC60  C0A870  \\\n",
      "0  2013010101     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "1  2013010102     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "2  2013010103     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "3  2013010104     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "4  2013010105     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "\n",
      "   466920  ...  C0A9I1  C0AD50  C0A9B0  C0A560  C0A950  C0A940  C0A570  \\\n",
      "0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "1     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "2     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "3     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "4     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "\n",
      "   C0A980  C0A9C0  C0AD40  \n",
      "0     0.0     0.0     0.0  \n",
      "1     0.0     0.0     0.0  \n",
      "2     0.0     0.0     0.0  \n",
      "3     0.0     0.0     0.0  \n",
      "4     0.0     0.0     0.0  \n",
      "\n",
      "[5 rows x 46 columns]\n",
      "(35064, 46)\n",
      "\n",
      "Merged:\n",
      "         date  466880_qpe  466880_obs\n",
      "0  2014010108         0.0         0.0\n",
      "1  2014010109         0.0         0.0\n",
      "2  2014010110         0.0         0.0\n",
      "3  2014010111         0.0         0.0\n",
      "4  2014010112         0.0         0.0\n",
      "(25136, 3)\n"
     ]
    }
   ],
   "source": [
    "print('Station Precipitation:')\n",
    "y = pd.read_csv('data/t1hr.csv')\n",
    "print(y.head())\n",
    "print(y.shape)\n",
    "\n",
    "print('')\n",
    "print('Merged:')\n",
    "ys_466880 = qpe.loc[:,['date','466880']].merge(y.loc[:,['date','466880']], suffixes=('_qpe','_obs'), on='date')\n",
    "print(ys_466880.head())\n",
    "print(ys_466880.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "466880\n",
      "         date  466880_qpe  466880_obs\n",
      "0  2014010108         0.0         0.0\n",
      "1  2014010109         0.0         0.0\n",
      "2  2014010110         0.0         0.0\n",
      "3  2014010111         0.0         0.0\n",
      "4  2014010112         0.0         0.0\n",
      "(25136, 3)\n",
      "466910\n",
      "         date  466910_qpe  466910_obs\n",
      "0  2014010108         0.0         0.0\n",
      "1  2014010109         0.0         0.0\n",
      "2  2014010110         0.0         0.0\n",
      "3  2014010111         0.0         0.0\n",
      "4  2014010112         0.0         0.0\n",
      "(25136, 3)\n",
      "466920\n",
      "         date  466920_qpe  466920_obs\n",
      "0  2014010108         0.0         0.0\n",
      "1  2014010109         0.0         0.0\n",
      "2  2014010110         0.0         0.0\n",
      "3  2014010111         0.0         0.0\n",
      "4  2014010112         0.0         0.0\n",
      "(25136, 3)\n",
      "466930\n",
      "         date  466930_qpe  466930_obs\n",
      "0  2014010108         0.0         0.0\n",
      "1  2014010109         0.0         0.0\n",
      "2  2014010110         0.0         0.0\n",
      "3  2014010111         0.0         0.0\n",
      "4  2014010112         0.0         0.0\n",
      "(25136, 3)\n",
      "466940\n",
      "         date  466940_qpe  466940_obs\n",
      "0  2014010108         0.0         0.0\n",
      "1  2014010109         0.0         0.0\n",
      "2  2014010110         0.0         0.0\n",
      "3  2014010111         0.0         0.0\n",
      "4  2014010112         0.0         0.0\n",
      "(25136, 3)\n"
     ]
    }
   ],
   "source": [
    "# Do it for all stations\n",
    "ys = {}\n",
    "y = pd.read_csv('data/t1hr.csv')\n",
    "for id in stid:\n",
    "    ys[id] = qpe.loc[:,['date',id]].merge(y.loc[:,['date',id]], suffixes=('_qpe','_obs'), on='date')\n",
    "    \n",
    "for k,v in ys.items():\n",
    "    print(k)\n",
    "    print(v.head())\n",
    "    print(v.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have all data paired, we will proceed will performance metrics.\n",
    "\n",
    "## Performance Metrics\n",
    "\n",
    "For continuous output (the amount of precipitation), we calculate the `root-mean-squared-error (RMSE)` and `correlation coeeficient`. For categorical output, we use 30mm/hr as the threshold, and derive `confusion matrix` and other metrics (see [wikipedia](https://en.wikipedia.org/wiki/Confusion_matrix) for further details)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': None,\n",
       " 'true_positive': 8,\n",
       " 'false_positive': 17,\n",
       " 'false_negative': 15,\n",
       " 'true_negative': 25096,\n",
       " 'sensitivity': 0.35,\n",
       " 'specificity': 1.0,\n",
       " 'prevalence': 0.00091502,\n",
       " 'ppv': 0.32,\n",
       " 'npv': 0.9994,\n",
       " 'fpr': 0.0007,\n",
       " 'fnr': 0.6522,\n",
       " 'fdr': 0.68,\n",
       " 'FOR': 0.0006,\n",
       " 'accuracy': 0.9987,\n",
       " 'F1': 0.3333,\n",
       " 'MCC': 0.333,\n",
       " 'informedness': 0.35,\n",
       " 'markedness': 0.3194}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluate_binary(yt, yp, stid=None, ythresh=30.):\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    ytb = (yt>=ythresh)*1\n",
    "    ypb = (yp>=ythresh)*1\n",
    "    # Derive metrics\n",
    "    output = {'id':stid}\n",
    "    TN, FP, FN, TP = confusion_matrix(ytb, ypb).ravel()\n",
    "    output['true_positive'] = np.round(TP,2)\n",
    "    output['false_positive'] = np.round(FP,2)\n",
    "    output['false_negative'] = np.round(FN,2)\n",
    "    output['true_negative'] = np.round(TN,2)\n",
    "    output['sensitivity'] = np.round(TP/(TP+FN),2)\n",
    "    output['specificity'] = np.round(TN/(FP+TN),2)\n",
    "    output['prevalence'] = np.round((TP+FN)/(FN+TP+FP+TN),8)\n",
    "    output['ppv'] = np.round(TP/(TP+FP),4)\n",
    "    output['npv'] = np.round(TN/(TN+FN),4)\n",
    "    output['fpr'] = np.round(FP/(FP+TN),4)\n",
    "    output['fnr'] = np.round(FN/(FN+TP),4)\n",
    "    output['fdr'] = np.round(FP/(FP+TP),4)\n",
    "    output['FOR'] = np.round(FN/(TN+FN),4)\n",
    "    output['accuracy'] = np.round((TP+TN)/(FN+TP+FP+TN),4)\n",
    "    output['F1'] = np.round(2*TP/(2*TP+FP+FN),4)\n",
    "    output['MCC'] = np.round((TP*TN-FP*FN)/np.sqrt((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)),4)\n",
    "    output['informedness'] = np.round(output['sensitivity'] + output['specificity'] - 1,4)\n",
    "    output['markedness'] = np.round(output['ppv'] + output['npv'] -1,4)\n",
    "    return(output)\n",
    "    \n",
    "evaluate_binary(ys['466880']['466880_obs'], ys['466880']['466880_qpe'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id  true_positive  false_positive  false_negative  true_negative  \\\n",
      "0  466880              8              17              15          25096   \n",
      "1  466910              3               7              23          25103   \n",
      "2  466920              7              21              15          25093   \n",
      "3  466930              9               4              25          25098   \n",
      "4  466940              3               5              16          25112   \n",
      "\n",
      "   sensitivity  specificity  prevalence     ppv     npv     fpr     fnr  \\\n",
      "0         0.35          1.0    0.000915  0.3200  0.9994  0.0007  0.6522   \n",
      "1         0.12          1.0    0.001034  0.3000  0.9991  0.0003  0.8846   \n",
      "2         0.32          1.0    0.000875  0.2500  0.9994  0.0008  0.6818   \n",
      "3         0.26          1.0    0.001353  0.6923  0.9990  0.0002  0.7353   \n",
      "4         0.16          1.0    0.000756  0.3750  0.9994  0.0002  0.8421   \n",
      "\n",
      "      fdr     FOR  accuracy      F1     MCC  informedness  markedness  \n",
      "0  0.6800  0.0006    0.9987  0.3333  0.3330          0.35      0.3194  \n",
      "1  0.7000  0.0009    0.9988  0.1667  0.1855          0.12      0.2991  \n",
      "2  0.7500  0.0006    0.9986  0.2800  0.2813          0.32      0.2494  \n",
      "3  0.3077  0.0010    0.9988  0.3830  0.4276          0.26      0.6913  \n",
      "4  0.6250  0.0006    0.9992  0.2222  0.2430          0.16      0.3744  \n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for i in stid:\n",
    "    ytlab = i+'_obs'\n",
    "    yplab = i+'_qpe'\n",
    "    tmp = evaluate_binary(ys[i][ytlab], ys[i][yplab], stid=i)\n",
    "    results.append(tmp)\n",
    "\n",
    "results = pd.DataFrame(results)\n",
    "results.to_csv('data/eval_cwbqpe.csv', index=False)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the ML approach\n",
    "\n",
    "We use the same evaluation metrics on our ML approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date  y  y_pred   y0        y1            y2            y3   y4\n",
      "0  2013010112  1       1  1.0  0.989957  7.748604e-07  2.980232e-08  0.0\n",
      "1  2013010113  1       1  1.0  0.999817  5.960464e-08  0.000000e+00  0.0\n",
      "2  2013010114  1       1  1.0  0.998764  2.235174e-06  2.980232e-08  0.0\n",
      "3  2013010115  1       0  1.0  0.067918  2.980232e-07  0.000000e+00  0.0\n",
      "4  2013010116  1       1  1.0  0.976671  0.000000e+00  0.000000e+00  0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': '466880',\n",
       " 'true_positive': 16,\n",
       " 'false_positive': 107,\n",
       " 'false_negative': 11,\n",
       " 'true_negative': 30187,\n",
       " 'sensitivity': 0.59,\n",
       " 'specificity': 1.0,\n",
       " 'prevalence': 0.00089047,\n",
       " 'ppv': 0.1301,\n",
       " 'npv': 0.9996,\n",
       " 'fpr': 0.0035,\n",
       " 'fnr': 0.4074,\n",
       " 'fdr': 0.8699,\n",
       " 'FOR': 0.0004,\n",
       " 'accuracy': 0.9961,\n",
       " 'F1': 0.2133,\n",
       " 'MCC': 0.2764,\n",
       " 'informedness': 0.59,\n",
       " 'markedness': 0.1297}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluate_mlc(yt, yp, stid=None, ytth=3, ypth=1):\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    ytb = (yt>ytth)*1\n",
    "    ypb = (yp>ypth)*1\n",
    "    # Derive metrics\n",
    "    output = {'id':stid}\n",
    "    TN, FP, FN, TP = confusion_matrix(ytb, ypb).ravel()\n",
    "    output['true_positive'] = np.round(TP,2)\n",
    "    output['false_positive'] = np.round(FP,2)\n",
    "    output['false_negative'] = np.round(FN,2)\n",
    "    output['true_negative'] = np.round(TN,2)\n",
    "    output['sensitivity'] = np.round(TP/(TP+FN),2)\n",
    "    output['specificity'] = np.round(TN/(FP+TN),2)\n",
    "    output['prevalence'] = np.round((TP+FN)/(FN+TP+FP+TN),8)\n",
    "    output['ppv'] = np.round(TP/(TP+FP),4)\n",
    "    output['npv'] = np.round(TN/(TN+FN),4)\n",
    "    output['fpr'] = np.round(FP/(FP+TN),4)\n",
    "    output['fnr'] = np.round(FN/(FN+TP),4)\n",
    "    output['fdr'] = np.round(FP/(FP+TP),4)\n",
    "    output['FOR'] = np.round(FN/(TN+FN),4)\n",
    "    output['accuracy'] = np.round((TP+TN)/(FN+TP+FP+TN),4)\n",
    "    output['F1'] = np.round(2*TP/(2*TP+FP+FN),4)\n",
    "    output['MCC'] = np.round((TP*TN-FP*FN)/np.sqrt((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)),4)\n",
    "    output['informedness'] = np.round(output['sensitivity'] + output['specificity'] - 1,4)\n",
    "    output['markedness'] = np.round(output['ppv'] + output['npv'] -1,4)\n",
    "    return(output)\n",
    "\n",
    "\n",
    "MLDIR = '../ws.cwb/evaluate_cv/'\n",
    "MLEXT = '_e20cv_mlc_ys.csv'\n",
    "\n",
    "tmp = pd.read_csv(MLDIR+stid[0]+MLEXT)\n",
    "print(tmp.head())\n",
    "\n",
    "evaluate_mlc(yt=tmp['y'], yp=tmp['y_pred'], stid=stid[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id  true_positive  false_positive  false_negative  true_negative  \\\n",
      "0  466880             16             107              11          30187   \n",
      "1  466910             29             257              11          29766   \n",
      "2  466920             13              74              18          30063   \n",
      "3  466930             34             207               8          30806   \n",
      "4  466940              9             100              16          30440   \n",
      "\n",
      "   sensitivity  specificity  prevalence     ppv     npv     fpr     fnr  \\\n",
      "0         0.59         1.00    0.000890  0.1301  0.9996  0.0035  0.4074   \n",
      "1         0.72         0.99    0.001331  0.1014  0.9996  0.0086  0.2750   \n",
      "2         0.42         1.00    0.001028  0.1494  0.9994  0.0025  0.5806   \n",
      "3         0.81         0.99    0.001352  0.1411  0.9997  0.0067  0.1905   \n",
      "4         0.36         1.00    0.000818  0.0826  0.9995  0.0033  0.6400   \n",
      "\n",
      "      fdr     FOR  accuracy      F1     MCC  informedness  markedness  \n",
      "0  0.8699  0.0004    0.9961  0.2133  0.2764          0.59      0.1297  \n",
      "1  0.8986  0.0004    0.9911  0.1779  0.2690          0.71      0.1010  \n",
      "2  0.8506  0.0006    0.9970  0.2203  0.2491          0.42      0.1488  \n",
      "3  0.8589  0.0003    0.9931  0.2403  0.3362          0.80      0.1408  \n",
      "4  0.9174  0.0005    0.9962  0.1343  0.1711          0.36      0.0821  \n"
     ]
    }
   ],
   "source": [
    "# Loop through stid\n",
    "results_ml = []\n",
    "for i in stid:\n",
    "    ysml = pd.read_csv(MLDIR + i + MLEXT)\n",
    "    tmp = evaluate_mlc(ysml['y'], ysml['y_pred'], stid=i)\n",
    "    results_ml.append(tmp)\n",
    "\n",
    "results_ml = pd.DataFrame(results_ml)\n",
    "results_ml.to_csv('data/eval_ml.csv', index=False)\n",
    "print(results_ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
