{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Features from QPESUMS with Convolutional Autoencoder\n",
    "\n",
    "In earlier analysis, we use PCA as a common linear dimension reduction technique. Here, we want to take advantage of the recent development of deep learning, using **convolutional autoencoder** as a nonlinear feature extration tool.\n",
    "\n",
    "\n",
    "### Autoencoder\n",
    "\n",
    "Autoencoders are widely used unsupervised application of neural networks whose original purpose is to find latent lower dimensional state-spaces of datasets, but they are also capable of solving other problems, such as image denoising, enhancement or colourization.\n",
    "\n",
    "The main idea behind Autoencoders is to reduce the input into a latent state-space with fewer dimensions and then try to reconstruct the input from this representation. The first part is called encoding and the second step is the decoding phase. By reducing the number of variables which represent the data, we force the model to learn how to keep only meaningful information, from which the input is reconstructable. It can also be viewed as a compression technique.\n",
    "\n",
    "<img src='figures/ae_illustrate.png' />\n",
    "\n",
    "\n",
    "\\[References\\]\n",
    "- [Aligning hand-written digits with Convolutional Autoencoders](https://towardsdatascience.com/aligning-hand-written-digits-with-convolutional-autoencoders-99128b83af8b)\n",
    "- [Autoencoders — Deep Learning bits #1](https://hackernoon.com/autoencoders-deep-learning-bits-1-11731e200694)\n",
    "- [Autoencoders — Introduction and Implementation in TF](https://towardsdatascience.com/autoencoders-introduction-and-implementation-3f40483b0a85)\n",
    "- [Deconvolution and Checkerboard Artifacts](https://distill.pub/2016/deconv-checkerboard/)\n",
    "- [Up-sampling with Transposed Convolution](https://medium.com/activating-robotic-minds/up-sampling-with-transposed-convolution-9ae4f2df52d0)\n",
    "\n",
    "\n",
    "### Problem declaration\n",
    "\n",
    "Here we use AE as a tool of feature extraction on the QPESUMS dataset, so let's see how it performs. Hence we need the basic tool to read in QPESUMS data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Input processing '''\n",
    "# Scan QPESUMS data in *.npy: 6*275*162 \n",
    "def search_dbz(srcdir):\n",
    "    import pandas as pd\n",
    "    fileinfo = []\n",
    "    for subdir, dirs, files in os.walk(srcdir, followlinks=True):\n",
    "        for f in files:\n",
    "            if f.endswith('.npy'):\n",
    "                # Parse file name for time information\n",
    "                furi = os.path.join(subdir, f)\n",
    "                finfo = f.split('.')\n",
    "                ftime = finfo[0]\n",
    "                #logging.debug([furi] + finfo[1:3])\n",
    "                fileinfo.append([furi, ftime])\n",
    "    results = pd.DataFrame(fileinfo, columns=['furi', 'timestamp'])\n",
    "    results = results.sort_values(by=['timestamp']).reset_index(drop=True)\n",
    "    return(results)\n",
    "\n",
    "# Read uris containing QPESUMS data in the format of 6*275*162 \n",
    "def loadDBZ(flist, to_log=False):\n",
    "    ''' Load a list a dbz files (in npy format) into one numpy array. '''\n",
    "    xdata = []\n",
    "    for f in flist:\n",
    "        tmp = np.load(f)\n",
    "        # Append new record\n",
    "        if tmp is not None:            # Append the flattened data array if it is not None\n",
    "            xdata.append(tmp.flatten())\n",
    "    x = np.array(xdata, dtype=np.float32)\n",
    "    # Convert to log space if specified\n",
    "    if to_log:\n",
    "        x = np.log(x+1)\n",
    "    # done\n",
    "    return(x)\n",
    "\n",
    "def data_generator_ae(flist, batch_size, to_log=False):\n",
    "    ''' Data generator for batched processing. '''\n",
    "    nSample = len(flist)\n",
    "    # This line is just to make the generator infinite, keras needs that    \n",
    "    while True:\n",
    "        batch_start = 0\n",
    "        batch_end = batch_size\n",
    "        while batch_start < nSample:\n",
    "            limit = min(batch_end, nSample)\n",
    "            X = loadDBZ(flist[batch_start:limit], to_log)\n",
    "            #print(X.shape)\n",
    "            yield (X,X) #a tuple with two numpy arrays with batch_size samples     \n",
    "            batch_start += batch_size   \n",
    "            batch_end += batch_size\n",
    "    # End of generator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoding the QPESUMS on Itself\n",
    "\n",
    "It means we want the decoded data is as similar to the original as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoencoder model\n",
    "def init_ae_mse(input_shape):\n",
    "    # Define input layer\n",
    "    input_data = Input(shape=input_shape)  # adapt this if using `channels_first` image data format\n",
    "    # Define encoder layers\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same', name='encoder_conv1', data_format='channels_first')(input_data)\n",
    "    x = MaxPooling2D((5, 3), name='encoder_maxpool1', data_format='channels_first')(x)\n",
    "    x = Conv2D(16, (3, 3), activation='relu', padding='same', name='encoder_conv2', data_format='channels_first')(x)\n",
    "    x = MaxPooling2D((1, 3), name='encoder_maxpool2', data_format='channels_first')(x)\n",
    "    x = Conv2D(8, (3, 3), activation='relu', padding='same', name='encoder_conv3', data_format='channels_first')(x)\n",
    "    x = MaxPooling2D((1, 3), name='encoder_maxpool3', data_format='channels_first')(x)\n",
    "    x = Conv2D(4, (3, 3), activation='relu', padding='same', name='encoder_conv4', data_format='channels_first')(x)\n",
    "    encoded = MaxPooling2D((5, 3), name='encoder_maxpool4', data_format='channels_first')(x)\n",
    "    #encoded = x\n",
    "    # Define decoder layers\n",
    "    x = Conv2D(4, (3, 3), activation='relu', padding='same', name='decoder_conv1', data_format='channels_first')(encoded)\n",
    "    x = UpSampling2D((5, 3), name='decoder_upsamp1', data_format='channels_first')(x)\n",
    "    x = Conv2D(8, (3, 3), activation='relu', padding='same', name='decoder_conv2', data_format='channels_first')(x)\n",
    "    x = UpSampling2D((1, 3), name='decoder_upsamp2', data_format='channels_first')(x)\n",
    "    x = Conv2D(16, (3, 3), activation='relu', padding='same', name='decoder_conv3', data_format='channels_first')(x)\n",
    "    x = UpSampling2D((1, 3), name='decoder_upsamp3', data_format='channels_first')(x)\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same', name='decoder_conv4', data_format='channels_first')(x)\n",
    "    x = UpSampling2D((5, 3), name='decoder_upsamp4', data_format='channels_first')(x)\n",
    "    decoded = Conv2D(6, (3, 3), activation='sigmoid', name='decoder_output', padding='same', data_format='channels_first')(x)\n",
    "    # Define autoencoder\n",
    "    autoencoder = Model(input_data, decoded)\n",
    "    #autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "    autoencoder.compile(optimizer='adam', loss='mse', metrics=['cosine_proximity','binary_crossentropy'])\n",
    "    # Encoder\n",
    "    encoder = Model(input_data, encoded)\n",
    "    return((autoencoder, encoder))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
